{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5abcb1f9-8e23-4838-8462-7daff5bffb40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "awsAccessKeyId = spark.conf.get(\"awsAccessKeyId\")\n",
    "awsSecretKey = spark.conf.get(\"awsSecretKey\")\n",
    "kinesisStreamName = spark.conf.get(\"kinesisStreamName\")\n",
    "kinesisRegion = spark.conf.get(\"kinesisRegion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd003325-159d-4efe-b688-3eaed50e7bf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
    "from pyspark.sql.functions import col, from_json, current_timestamp, count, when, coalesce, lit, window\n",
    "import dlt\n",
    "\n",
    "# Define schema for the JSON data\n",
    "schema = StructType([\n",
    "  StructField(\"post_id\", StringType()), \n",
    "  StructField(\"platform\", StringType()),\n",
    "  StructField(\"engagement_type\", StringType()),\n",
    "  StructField(\"user_id\", StringType()),\n",
    "  StructField(\"timestamp\", TimestampType())\n",
    "])\n",
    "\n",
    "# Read streaming data from Kinesis\n",
    "@dlt.table\n",
    "def social_media_engagement_streaming_bronze():\n",
    "    return (\n",
    "        spark\n",
    "        .readStream\n",
    "        .format(\"kinesis\")\n",
    "        .option(\"streamName\", kinesisStreamName)\n",
    "        .option(\"initialPosition\", \"trim_horizon\")\n",
    "        .option(\"awsAccessKey\", awsAccessKeyId)\n",
    "        .option(\"awsSecretKey\", awsSecretKey)\n",
    "        .option(\"region\", kinesisRegion)\n",
    "        .load()\n",
    "        # Parse JSON data and extract fields\n",
    "        .withColumn(\"value\", from_json(col(\"data\").cast(\"string\"), schema))\n",
    "        .withColumn(\"process_time\", current_timestamp())\n",
    "        .select(\"value.post_id\", \"value.platform\", \"value.engagement_type\", \"value.user_id\", \"value.timestamp\", \"process_time\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "118dc4a8-63fa-4339-bda2-f51ef0cb3efe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "@dlt.table\n",
    "def social_media_engagement_streaming_silver():\n",
    "    return (\n",
    "        dlt.read_stream(\"social_media_engagement_streaming_bronze\")\n",
    "        .withColumn(\"platform\", coalesce(col(\"platform\"), lit(\"unknown_platform\")))\n",
    "        .withColumn(\"engagement_type\", coalesce(col(\"engagement_type\"), lit(\"unknown_engagement\")))\n",
    "        .withColumn(\"user_id\", coalesce(col(\"user_id\"), lit(\"unknown_user\")))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65871b1b-3a74-4179-be4a-11f66770f60f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window\n",
    "\n",
    "@dlt.table\n",
    "def social_media_engagement_streaming_gold():\n",
    "    return (\n",
    "        dlt.read_stream(\"social_media_engagement_streaming_silver\")\n",
    "        # Apply watermark to handle late data by one minute\n",
    "        .withWatermark(\"timestamp\", \"1 minute\")\n",
    "        # Sliding window by 5 minutes\n",
    "        groupBy(col(\"post_id\"), col(\"platform\"), window(col(\"timestamp\"), \"2 minutes\"))\n",
    "        # Count the number of likes, shares, and comments within the window\n",
    "        # per post_id and platform\n",
    "        .agg(\n",
    "            count(when(col(\"engagement_type\").equalTo(\"like\"), 1)).alias(\"likes\"),\n",
    "            count(when(col(\"engagement_type\").equalTo(\"share\"), 1)).alias(\"shares\"),\n",
    "            count(when(col(\"engagement_type\").equalTo(\"comment\"), 1)).alias(\"comments\"),\n",
    "            count(\"*\").alias(\"total_engagements\")\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76ce43ec-df4b-446a-beca-c2f1c12523d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
    "# from pyspark.sql.functions import col, from_json, current_timestamp, count, when\n",
    "\n",
    "# # Define schema for the JSON data\n",
    "# schema = StructType([\n",
    "#   StructField(\"post_id\", StringType(), True), \n",
    "#   StructField(\"platform\", StringType(), True),\n",
    "#   StructField(\"engagement_type\", StringType(), True),\n",
    "#   StructField(\"user_id\", StringType(), True),\n",
    "#   StructField(\"timestamp\", TimestampType())\n",
    "# ])\n",
    "\n",
    "# # Read streaming data from Kinesis\n",
    "# (\n",
    "#   spark\n",
    "#     .readStream\n",
    "#     .format(\"kinesis\")\n",
    "#     .option(\"streamName\", kinesisStreamName)\n",
    "#     .option(\"initialPosition\", \"trim_horizon\")\n",
    "#     .option(\"awsAccessKey\", awsAccessKeyId)\n",
    "#     .option(\"awsSecretKey\", awsSecretKey)\n",
    "#     .option(\"region\", kinesisRegion)\n",
    "#   .load()\n",
    "#   # Parse JSON data and extract fields\n",
    "#   .withColumn(\"value\", from_json(col(\"data\").cast(\"string\"), schema))\n",
    "#   .withColumn(\"process_time\", current_timestamp())\n",
    "#   .select(\"value.post_id\", \"value.platform\", \"value.engagement_type\", \"value.user_id\", \"value.timestamp\", \"process_time\")\n",
    "#     .writeStream\n",
    "#     .queryName(\"social_media_streaming_engagemen_bronzet\")\n",
    "#     .option(\"checkpointLocation\", \"/Volumes/workspace/default/checkpoint/kinesis_stream_bronze\")\n",
    "#     .trigger(availableNow=True)  # Trigger the query to process available data\n",
    "#     .outputMode(\"append\")  # Append new records to the table \n",
    "#   .toTable(\"workspace.default.social_media_engagement_streaming_bronze\")  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dd59d37-bacc-4ab6-a743-7443079ad0e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "# # Read streaming data from the bronze table\n",
    "# (\n",
    "#   spark\n",
    "#     .readStream\n",
    "#       .table(\"workspace.default.social_media_engagement_streaming_bronze\")\n",
    "#       # Handle null values by replacing them with default values\n",
    "#       .withColumn(\"post_id\", coalesce(col(\"post_id\"), lit(\"unknown post\")))\n",
    "#       .withColumn(\"platform\", coalesce(col(\"platform\"), lit(\"unknown_platform\")))\n",
    "#       .withColumn(\"engagement_type\", coalesce(col(\"engagement_type\"), lit(\"unknown_engagement\")))\n",
    "#       .withColumn(\"user_id\", coalesce(col(\"user_id\"), lit(\"unknown_user\")))\n",
    "#     # Write the cleaned data to the silver table\n",
    "#     .writeStream\n",
    "#       .queryName(\"social_media_engagement_streaming_silver\")\n",
    "#       .option(\"checkpointLocation\", \"/Volumes/workspace/default/checkpoint/kinesis_stream_silver\")\n",
    "#       .trigger(availableNow=True)\n",
    "#       .outputMode(\"append\")\n",
    "#     .toTable(\"workspace.default.social_media_engagement_streaming_silver\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9224a67a-9ff8-454e-accd-4ed0ce426ebb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import window\n",
    "\n",
    "# (\n",
    "#   spark\n",
    "#     .readStream\n",
    "#     # Read the streaming data from the silver table\n",
    "#     .table(\"workspace.default.social_media_engagement_streaming_silver\")\n",
    "#     # Apply watermark to handle late data by one minute\n",
    "#     .withWatermark(\"timestamp\", \"1 minute\")\n",
    "#     # Sliding window by 5 minutes\n",
    "#     .groupBy(\"post_id\", \"platform\", window(col(\"timestamp\"), \"2 minutes\"))\n",
    "#     # Count the number of likes, shares, and comments within the window\n",
    "#     # per post_id and platform\n",
    "#     .agg(\n",
    "#       count(when(col(\"engagement_type\") == \"like\", 1)).alias(\"likes\"),\n",
    "#       count(when(col(\"engagement_type\") == \"share\", 1)).alias(\"shares\"),\n",
    "#       count(when(col(\"engagement_type\") == \"comment\", 1)).alias(\"comments\"),\n",
    "#       count(\"*\").alias(\"total_engagements\")\n",
    "#     )\n",
    "#     # Write the aggregated data to the gold table\n",
    "#     .writeStream\n",
    "#     .queryName(\"social_media_engagement_streaming_gold\")\n",
    "#     .option(\"checkpointLocation\", \"/Volumes/workspace/default/checkpoint/kinesis_stream_gold\")\n",
    "#     .trigger(availableNow=True) \n",
    "#     .outputMode(\"append\")\n",
    "#     .toTable(\"workspace.default.social_media_engagement_streaming_gold\")\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1291449321898135,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Streaming ETL Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
